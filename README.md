 # âœ… Softnerve Book Content Enhancement Platform

This project implements a robust, AI-driven content pipeline designed to scrape, rewrite, review, rank, and continuously improve book chapters. It leverages human feedback and a sophisticated multi-model selection strategy using **Reinforcement Learning (RL)** and **Multi-Armed Bandits (MAB)**, specifically **Thompson Sampling**, to optimize content quality.

---

## ðŸš€ Features

* **ðŸ“š Web Scraping**: Automatically scrapes target book chapters using `playwright` and `bs4`.
* **âœï¸ AI-Powered Rewriting & Revision**: Utilizes **Anthropic Claude** for content rewriting and incorporates human feedback for iterative improvements. The system is also **Gemini-ready** for future integration.
* **ðŸ§  Dynamic Model Selection**: Employs **Thompson Sampling Multi-Armed Bandit (MAB)** for intelligent selection between AI models (e.g., Claude, Gemini) based on their performance metrics.
* **ðŸ” Human-in-the-Loop Feedback**: Integrates a clear human feedback loop to guide content refinement and ensure quality.
* **ðŸ† RL-Based Version Ranking**: Ranks different content versions based on real-time feedback scores, allowing for continuous improvement and selection of the best outputs.
* **ðŸ’¾ Vector Retrieval**: Uses **ChromaDB** for efficient storage and retrieval of content versions and embeddings.
* **âœ… Modular and Reusable**: Designed as a modular Python pipeline for easy maintenance and expansion.

---

## ðŸ› ï¸ Tech Stack

This platform is built with a powerful combination of modern AI and data management technologies:

| Layer            | Technologies Used                                  | AI Models                                   |
| :--------------- | :------------------------------------------------- | :------------------------------------------ |
| **Backend** | Python 3.12                                        |                                             |
| **AI Models** |                                                    | **Anthropic Claude**, **Gemini** (stub for future), **BGE-Base embedding** |
| **Web Scraping** | `playwright`, `bs4`                                |                                             |
| **LLM Access** | `anthropic`, `openai`                              |                                             |
| **Vector Store** | `chromadb`                                         |                                             |
| **RL/MAB** | Custom RL Search Agent & **Thompson Sampling** Logic |                                             |
| **Storage** | Local JSON files + Screenshot logs                 |                                             |
| **Version Control** | Git                                                |                                             |

---

## ðŸ“‚ Folder Structure

```bash
Softnerve_book/
â”‚
â”œâ”€â”€ ai_processor.py         # Claude+Gemini editor + MAB logic for content generation
â”œâ”€â”€ apply_feedback.py       # Applies human feedback to iteratively improve content
â”œâ”€â”€ common_pipeline.py      # Orchestrates the full content generation and refinement process
â”œâ”€â”€ config.py               # Centralized configuration for environment variables and constants
â”œâ”€â”€ rl_search.py            # Reinforcement Learning agent to rank content versions based on rewards
â”œâ”€â”€ scraper.py              # Handles web scraping of book chapter content
â”œâ”€â”€ mab_stats.json          # Stores statistics for Multi-Armed Bandit (MAB) model performance (e.g., alpha, beta for Thompson Sampling)
â”œâ”€â”€ rating.txt              # Manual score logs for content versions (for human review)
â”œâ”€â”€ requirements.txt        # Lists all required Python libraries and dependencies
â”œâ”€â”€ output/                 # Directory for generated output (e.g., spun, revised content)
â”œâ”€â”€ screenshots/            # Stores visual screenshots of scraped chapters for review
â””â”€â”€ .git/                   # Git repository metadata
```
## ðŸ” Full Pipeline Overview
The content enhancement pipeline follows a systematic multi-stage process:

1. Scrape Content:

- A URL is pulled from config.py.

- HTML content is scraped and then converted to raw text.

> Output File: raw_scraped.txt

2. Spin Content (AI Rewriting):

- Anthropic Claude (or a selected model via MAB) rewrites the raw content based on predefined prompts.

> Output File: edited_spin.txt

3. Review Content (AI Feedback Generation):

- Claude or Gemini generates improvement suggestions for the rewritten content.

> Output File: review_feedback.json

4. Human Feedback Loop:

- apply_feedback.py processes human feedback to refine the content.

> Output File: final_revised.txt

5. Reinforcement Ranking:

- rl_search.py utilizes an RL agent to rank all generated content versions based on accumulated feedback scores.

> Output File: feedback_rewards.json (Reward scores for RL ranking)

6. Model Selection (Thompson Sampling MAB):

- The system uses Thompson Sampling within the MAB framework to dynamically select the best-performing AI model (e.g., Claude vs. Gemini) for the next iteration, adapting based on success rates over time.

Example **mab_stats.json** structure:
```
{
  "claude": [5, 2],  // alpha (successes), beta (failures) for Claude
  "gemini": [2, 5]   // alpha, beta for Gemini
}
```
## How to Run
Follow these steps to set up and run the content enhancement pipeline:
1. Install dependencies:
   ```
   pip install -r requirements.txt
   ```
2. Set environment variables:
Make sure to replace your_key_here with your actual API keys
```
export ANTHROPIC_API_KEY=your_key_here
export OPENAI_API_KEY=your_key_here
```
3. Run the main pipeline:
This script orchestrates the scraping, AI rewriting, and initial feedback generation.
```
python common_pipeline.py
```
4. Apply feedback:
After reviewing the content and providing feedback, run this to apply the revisions.
```
python apply_feedback.py
```
5. Perform reinforcement-based retrieval:
This step handles the ranking and selection of the best content versions.
```

python rl_search.py
```
### Flowchart :
```

Start
    â†“
Scrape Chapter Text (WebScraper using Playwright) â†’ raw_scraped.txt
    â†“
Store Raw Content (raw_scraped.txt)
    â†“
Select AI Model (Claude / Gemini) â†’ via Thompson Sampling (MAB)
    â†“
Rewrite Content with AI â†’ edited_spin.txt
    â†“
Generate Feedback Suggestions (Claude/Gemini) â†’ review_feedback.json
    â†“
Apply Human Feedback (apply_feedback.py) â†’ final_revised.txt
    â†“
Rank Versions Using RL (rl_search.py) â†’ feedback_rewards.json
    â†“
Display Ranked Versions â†’ Save Best Version
    â†“
End
```
## ðŸ“ˆ Model Selection: Thompson Sampling
The pipeline uses a Multi-Armed Bandit approach to select between models dynamically, adapting based on success rates over time.
```
"claude": [5, 2],  # alpha, beta
"gemini": [2, 5]
```


